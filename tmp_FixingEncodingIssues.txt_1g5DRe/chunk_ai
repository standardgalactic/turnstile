            soup = BeautifulSoup(content,
'html.parser'
)
            text_parts.append(soup.get_text(separator=
"\n"
, strip=
True
))
else
:
            text_parts.append(content)
return
"\n\n"
.join(text_parts)
def
extract_text_from_pdf
(
pdf_path
):
"""Extracts text from PDF using PyMuPDF."""
text =
""
try
:
        doc = fitz.
open
(pdf_path)
for
page
in
doc:
            text += page.get_text(
"text"
) +
"\n"
except
Exception
as
e:
print
(
f"Error extracting PDF
{pdf_path}
:
{e}
")
return
text
def
extract_text_from_epub
(
epub_path
):
"""Extracts text from EPUB using ebooklib + BeautifulSoup."""
text =
""
try
:
        book = epub.read_epub(epub_path)
for
item
in
book.get_items():
if
item.get_type() == ebooklib.ITEM_DOCUMENT:
                soup = BeautifulSoup(item.get_content(),
"html.parser"
)
                text += soup.get_text() +
"\n"
except
Exception
as
e:
print
(
f"Error extracting EPUB
{epub_path}
:
{e}
")
return
text
def
save_text
(
text, source_path
):
    output_file = os.path.splitext(source_path)[
0
] +
".txt"
try
:
with
open
(output_file,
"w"
, encoding=
"utf-8"
