uh, those values into decision making?
And by the way, do you know, um, Nora Bateson and 
her work in what's called, uh, warm Data Labs?
Mm-hmm.
Yes, I've heard of, I've not worked 
directly, but yes. Okay. But go ahead. What,  
what about, uh, data and feelings? 
The integration of that? Mm-hmm.
Yeah. Uh, first of all, I think 
we're all experts of our feelings.
Uh, and so that is actually what can easily 
resonate with our fellow citizens. Had we  
start our Uber consultation with, 
what's your ideal economic model  
for sharing economy versus extractive gig 
economy? Uh, probably nobody will come,  
right? Because it was, um, like. Extremely 
abstract, but feeling is not abstract at all.
Feeling is very personal. And so based on 
feeling, then people want to take care of  
each other's feelings. So you can see 
like the Uber driver, the taxi drivers,  
the passengers, the people worrying 
about rural development and someone,  
um, they all center around shared feelings. And 
so naturally when people start proposing ideas,  
those idea that take care of everybody's 
feelings will float to the top.
And so this speaks to a very different ethical, 
uh, foundation of policy making. This is more  
about the ethics of care. That is to say, 
how much do we want to take care of each  
other instead of what's. Single abstract 
value, um, like in a scholar value sense,  
do we want to optimize? Right? Uh, and care 
also has the benefits of, um, its positive sum.
So if I take care of your ideas, then you 
are probably going to propose an idea that  
also take care of my feelings, uh, as opposed 
to if you put it to referendum or something  
as Uber did in other jurisdictions, 
maybe 51% people feel they have won,  
maybe 49, feel they have lost, but their 
feelings are hurt and are therefore more  
likely to engage in negative sum uh, 
conversations from that point onward.
So what did those projects, um, tell you about 
the divisiveness and polarization of the societies  
where they were enacted, and did people respond 
well to, to these technologies? Like, oh, I, this  
